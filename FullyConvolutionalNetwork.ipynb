{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lkgupta/my_project_dir/my_project_env/lib/python3.5/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/home/lkgupta/my_project_dir/my_project_env/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lkgupta/my_project_dir/my_project_env/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D, Input\n",
    "\n",
    "from keras.layers import Input, BatchNormalization, Activation\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "#from mlxtend.plotting import plot_confusion_matrix\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10533606760803238208\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15207951283342419975\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10010748388820436875\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4912535035238137563\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4058606711869938350\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12108627298704196966\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "[]\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsdf= pd.read_csv(\"worDwiseLabels/gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Script</th>\n",
       "      <th>translation</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_1.png</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>فروجنا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_2.png</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>المشوى</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_3.png</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>حلال</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_4.png</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>و</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_5.png</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>طازج</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    File_name  Script translation Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6\n",
       "0  word_1.png  Arabic      فروجنا        NaN        NaN        NaN        NaN\n",
       "1  word_2.png  Arabic      المشوى        NaN        NaN        NaN        NaN\n",
       "2  word_3.png  Arabic        حلال        NaN        NaN        NaN        NaN\n",
       "3  word_4.png  Arabic           و        NaN        NaN        NaN        NaN\n",
       "4  word_5.png  Arabic        طازج        NaN        NaN        NaN        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latin       42629\n",
       "Korean       4476\n",
       "Japanese     4108\n",
       "Arabic       3505\n",
       "Bangla       3214\n",
       "Chinese      2702\n",
       "Symbols      1133\n",
       "3               1\n",
       "Name: Script, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labelsdf['Script']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting ninimum size of images\n",
    "As the height and width of the input will decrease based on the values of kernel_size and strides. If the input image size is too small then we might fall short of the minimum required height and width (which should be greater than or equal to the kernel size) for the next convolution block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, min_side_len):\n",
    "\n",
    "    h, w, c = img.shape\n",
    "\n",
    "    # limit the min side maintaining the aspect ratio\n",
    "    if min(h, w) < min_side_len:\n",
    "        im_scale = float(min_side_len) / h if h < w else float(min_side_len) / w\n",
    "    else:\n",
    "        im_scale = 1.\n",
    "\n",
    "    new_h = int(h * im_scale)\n",
    "    new_w = int(w * im_scale)\n",
    "\n",
    "    re_im = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    return re_im  #, new_h / h, new_w / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_side_len = 64\n",
    "\n",
    "directory = 'wordWise_fcn/'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "for filename in os.listdir('wordWise'):\n",
    "    \n",
    "    img = cv2.imread(os.path.join('wordWise',filename))\n",
    "    new_im=resize_image(img, min_side_len)\n",
    "        \n",
    "    path = directory + filename\n",
    "    cv2.imwrite(path, new_im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing nas and unnecesary scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelsdf = labelsdf.dropna(axis=0, subset=['Script'])\n",
    "labelsdf = labelsdf.dropna(axis=0, subset=['File_name'])\n",
    "labelsdf=labelsdf[(labelsdf['Script'] !='Symbols')]\n",
    "labelsdf=labelsdf[(labelsdf['Script'] !='3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeDF=pd.merge(labelsdf, imageInfoDf, left_on=\"File_name\", right_on=\"fileName\")\n",
    "mergeDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 17.622824536376605,\n",
       " 1: 19.218419415059117,\n",
       " 2: 22.860103626943005,\n",
       " 3: 15.036027263875365,\n",
       " 4: 13.79982126899017,\n",
       " 5: 1.4489666658847264}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_index={0:'Arabic',1:'Bangla', 2:'Chinese', 3:'Japanese', 4:'Korean',5:'Latin'}\n",
    "#class_index={'Arabic': 0,'Bangla': 1,'Chinese': 2,'Japanese': 3,'Korean': 4,'Latin': 5}\n",
    "total=labelsdf['Script'].value_counts().sum()\n",
    "vc=labelsdf['Script'].value_counts()\n",
    "class_weights={val:total/vc[class_index[val]]for val in class_index}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsdf_train_val = labelsdf.sample(frac = 0.85) \n",
    "labelsdf_test = labelsdf.drop(labelsdf_train_val.index)\n",
    "\n",
    "#labelsdf_train_val = labelsdf_train_val.reset_index()\n",
    "\n",
    "labelsdf_train = labelsdf_train_val.sample(frac = 0.85) \n",
    "labelsdf_val = labelsdf_train_val.drop(labelsdf_train.index)\n",
    "\n",
    "labelsdf_train = labelsdf_train.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latin       5457\n",
       "Japanese     541\n",
       "Korean       527\n",
       "Arabic       448\n",
       "Bangla       432\n",
       "Chinese      336\n",
       "Symbols      135\n",
       "Name: Script, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labelsdf_val['Script']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latin       6467\n",
       "Korean       646\n",
       "Japanese     576\n",
       "Arabic       534\n",
       "Bangla       471\n",
       "Chinese      394\n",
       "Symbols      176\n",
       "3              1\n",
       "Name: Script, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labelsdf_test['Script']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latin       30705\n",
       "Korean       3303\n",
       "Japanese     2991\n",
       "Arabic       2523\n",
       "Bangla       2311\n",
       "Chinese      1972\n",
       "Symbols       822\n",
       "Name: Script, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labelsdf_train['Script']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDir = 'wordWise_fcn/'\n",
    "    \n",
    "# If you get out of memory error try reducing the batch size\n",
    "BATCH_SIZE=16\n",
    "\n",
    "train_it = Generator( imageDir,labelsdf_train,'File_name','Script', BATCH_SIZE=16, shuffle_images=True, image_min_side=32)\n",
    "val_it = Generator( imageDir,labelsdf_val,'File_name','Script', BATCH_SIZE=16, shuffle_images=True, image_min_side=32)\n",
    "test_it = Generator( imageDir,labelsdf_test,'File_name','Script', BATCH_SIZE=16, shuffle_images=True, image_min_side=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCN_model(len_classes=6, dropout_rate=0.2):\n",
    "    \n",
    "    input = tf.keras.layers.Input(shape=(None, None, 3))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)(input)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=1, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    " \n",
    "    x = tf.keras.layers.Conv2D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "    predictions = tf.keras.layers.Activation('softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=predictions)\n",
    "    \n",
    "    print(model.summary())\n",
    "    #print(f'Total number of layers: {len(model.layers)}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 128)   36992     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 6)     390       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, None, 6)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 6)     24        \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 47,454\n",
      "Trainable params: 46,994\n",
      "Non-trainable params: 460\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    fcn_model=FCN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "adam = Adam(lr=0.001)\n",
    "fcn_model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['Recall','Precision','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-fedfc8847a5a>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /home/lkgupta/my_project_dir/my_project_env/lib/python3.5/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "2738/2738 [==============================] - 9409s 3s/step - recall: 0.6713 - loss: 1.1080 - accuracy: 0.0000e+00 - precision: 0.7035 - val_accuracy: 0.0000e+00 - val_precision: 0.7113 - val_recall: 0.6965 - val_loss: 1.0830\n",
      "Epoch 2/5\n",
      "2738/2738 [==============================] - 11703s 4s/step - recall: 0.6939 - loss: 1.0641 - accuracy: 0.0000e+00 - precision: 0.7067 - val_accuracy: 0.0000e+00 - val_precision: 0.7822 - val_recall: 0.4609 - val_loss: 1.1375\n",
      "Epoch 3/5\n",
      "2738/2738 [==============================] - 15332s 6s/step - recall: 0.6920 - loss: 1.0431 - accuracy: 0.0000e+00 - precision: 0.7098 - val_accuracy: 0.0000e+00 - val_precision: 0.8138 - val_recall: 0.2687 - val_loss: 1.1812\n",
      "Epoch 4/5\n",
      " 986/2738 [=========>....................] - ETA: 1:27:04 - recall: 0.6883 - loss: 1.0317 - accuracy: 0.0000e+00 - precision: 0.7123"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=4)\n",
    "checkpoint = ModelCheckpoint('fcnModel.h5',save_best_only=True,monitor='val_loss')\n",
    "historyInc = fcn_model.fit_generator(generator=train_it,steps_per_epoch=len(train_it), \n",
    "                              validation_data=val_it, validation_steps=len(val_it),\n",
    "                              epochs=5,callbacks=[es,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = keras.models.load_model(\"fcnModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.057516098022461\n",
      "Test recall: 0.7014744877815247\n"
     ]
    }
   ],
   "source": [
    "score = fcn_model.evaluate_generator(test_it)\n",
    "print('Test loss:', score[0])\n",
    "print('Test recall:', score[1])\n",
    "#Confution Matrix and Classification Report\n",
    "Y_predFCN = fcn_model.predict(test_it) \n",
    "Y_predFCN = np.argmax(Y_predFCN, axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
